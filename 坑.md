

### 项目踩坑总结 (Troubleshooting & Lessons Learned)

在将XJTLU Web AI服务封装为API的过程中，我们遇到并解决了一系列问题。这段经历充满了挑战与反转，核心经验可以总结为以下几点：

*   **坑点 1：会话机制 (Session Mechanism)**
    *   **现象**: 直接代理请求无效，后端无响应。
    *   **原理**: 后端服务通过`sessionId`来追踪每一次对话。任何`completions`请求都必须关联一个有效的`sessionId`。
    *   **解决方案**: 逆向分析发现`saveSession`接口。最终采用**“按需创建，用完即焚”**的策略：为每个API请求创建一个全新的会话，并在请求结束后调用`delSession`接口将其删除。

*   **坑点 2：请求频率限制 (Rate Limiting)**
    *   **现象**: 频繁出现`429 Request too fast`错误，即使是看似合理的请求序列。
    *   **原理**: 服务器存在一个**全局API调用频率限制**。在极短的时间内（毫秒级）连续发起多次网络请求（例如，先`saveSession`，紧接着就`completions`），会被判定为异常行为。
    *   **解决方案**: 在连续的两次关键API调用（`saveSession`和`completions`）之间，人为地加入一个**固定的异步延迟** (`await asyncio.sleep(1.0)`)。这个延迟模拟了人类用户的自然操作间隔，有效规避了频率限制。**这是整个适配器能稳定运行的最关键的一步。**

*   **坑点 3：上下文处理与“毒性Prompt” (Context Handling & "Poisonous" Prompts)**
    *   **现象**: 当请求的上下文中包含从网页抓取的大段知识库（如维基百科）时，模型会返回通用的、表示无法理解的错误回复，或者直接返回`429`错误并附带“上下文过长”的误导性信息。
    *   **原理**: 这个问题的根源并非文本的“长度”，而是文本的“格式”。我们称之为“毒性Prompt”，其“毒性”来源包括：
        *   **不安全的URL格式**: 文本中包含的本地文件路径 (`file:///...`) 极有可能被后端WAF（Web应用防火墙）识别为路径遍历攻击并拦截。
        *   **未转义的特殊字符**: 复杂的Markdown、嵌套的括号、原始JSON字符串中的引号等，都可能破坏后端解析器的正常工作。
        *   我们曾错误地以为需要自己进行截断或复杂的提示词工程，但最终发现，**这些操作只是偶然地“净化”了这些毒性格式**。
    *   **解决方案**: 放弃在适配器端进行任何复杂的提示词工程或截断。**完全信任后端能够处理长文本**，我们只需将客户端发来的所有`messages`原封不动地拼接成一个巨大的`prompt`。事实证明，只要解决了“请求频率”问题，后端强大的处理能力就能正确理解这些大块文本。

*   **坑点 4：资源数量限制 (Resource Limiting)**
    *   **现象**: 在连续使用一段时间后，创建会话的请求开始失败，返回错误：`You have created 50 sessions, please delete some of them first!`。
    *   **原理**: 服务器对单个用户可持有的活动会话数量设置了上限（此例中为50个）。我们“按需创建”的策略如果不加以清理，会迅速耗尽这个配额。
    *   **解决方案**: 实现了**自动清理机制**。在每次`completions`请求的流式传输结束后，利用`finally`块启动一个“即发即忘”的后台任务，调用`delSession`接口删除刚刚使用过的会话，形成一个完美的“创建 -> 使用 -> 销毁”的生命周期闭环。

通过解决以上问题，我们最终构建了一个稳定、高效且完全无状态的逆向API适配器。
